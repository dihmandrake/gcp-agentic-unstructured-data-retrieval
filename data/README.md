# Data Directory

This directory contains all the data used for the RAG agent, including raw source documents, generated evaluation datasets, and evaluation results.

## Subdirectories

-   `/raw`: Contains the source documents for the agent.
-   `/processed`: Contains outputs from various scripts, such as evaluation results.

---

## File Descriptions

### `/raw/`

#### `medical_record_*.pdf`

-   **Purpose**: These PDF files are the raw, unstructured source documents that the RAG agent uses as its knowledge base. They contain synthetic medical records.
-   **How it's made**: These files are provided as the starter dataset for the project. They can also be generated by running `poetry run python scripts/generate_data.py`.

### `/processed/`

#### `golden_dataset.jsonl`

-   **Purpose**: This is the "golden" or "ground truth" dataset used for evaluating the agent's performance. Each line is a JSON object containing a piece of context from a source PDF, a question based on that context, and a known-correct "reference answer".
-   **How it's made**: This file is generated by the `scripts/generate_golden_dataset.py` script. The script reads the text from the PDFs in `/raw`, then uses a powerful generative model (Gemini) to create high-quality question-and-answer pairs based on the content of each document.

#### `eval_results.json`

-   **Purpose**: This file contains the detailed results from running the agent evaluation. It includes the agent's generated response for each question in the golden dataset, along with the scores for metrics like "groundedness" and "instruction_following".
-   **How it's made**: This file is generated by the `scripts/run_evaluation.py` script. The script runs the agent against each question in `golden_dataset.jsonl` and saves the agent's performance metrics to this file.
